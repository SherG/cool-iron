---
title: Google's "Code Red" Panic Over ChatGPT
path: /chatgpt-google-code-red
date: 2022-12-30
summary: A New York Times "gee whiz" story seems off.
tags: ['AI','Google']
---

Will ChatGPT set off an earthquake that swallows Google? Unlikely, despite a "gee whiz" article making the rounds.

_The New York Times_ claims that when ChatGPT was released, Google management <a href="https://archive.ph/https://www.nytimes.com/2022/12/21/technology/ai-chatgpt-google-search.html" target="blank">declared a "Code Red</a>" which was "akin to pulling the fire alarm." This is according to anonymous sources. 

The _Times_ also said they viewed a "memo" and listened to an "audio recordings" of a Google meeting, but they didn't publish these items. So readers can't assess these things for themselves. 

<img src="https://res.cloudinary.com/icecloud7/image/upload/v1672432331/SignalFox/nyt-chatgpt-code-red-google_mj93ec.png" />

The article quickly brings in the proverbial "_Some fear_ . . .".

<div style="padding-left: 2.5em;"><p>Some fear the company may be approaching a moment that the biggest Silicon Valley outfits dread — the arrival of an enormous technological change that could upend the business.</p></div>

But only a few paragaphs into the story we read that "the technology at the heart of OpenAI’s chat bot was developed by researchers at Google." (This is a reference to <a href="https://ai.googleblog.com/2022/01/lamda-towards-safe-grounded-and-high.html" target="blank">LaMDA</a>.) So it's hard to believe the search giant was flailing about, blindsided.

"Code Red" and "alarm" along with a few "experts" offering warnings, make for a sexy story. But is that drama inherent in the story?

The authors suggest that this technology could "cannibalize" Google's "lucrative search ads."

<div style="padding-left: 2.5em;"><p>If a chat bot is responding to queries with tight sentences, there is less reason for people to click on advertising links.</p></div>

## Engaging and Conversational

ChatGPT is engaging and fast. The sleek interface evokes proximity and emulates one-on-one conversation. Before you know it, you'll be adding niceties to your interactions, like "Merry Christmas ChatGPT."

"Assistant," as ChatGPT prefers to be called, seems confident and produces well-formed sentences and paragraphs, even when its answers include errors.<sup><a id="footnote-1-ref" href="#footnote-1">[1]</a></sup> It can correct itself and refine its answers in dialogue. 

After querying ChatGPT, you don't need to click through search results to find a suitable answer. The bot just delivers one answer, saving you time. It's easy to see the appeal especially for simple questions, recipes, and code troubleshooting. (See <a href="https://www.surgehq.ai/blog/googles-existential-threat-chatgpt-matches-googles-performance-on-informational-search-queries-and-smashes-it-on-coding" target="blank">this</a>.)

But ChatGPT doesn't _index_ content or crawl the web. It's not a search engine. It has a different mission than Google Search, and is at the opposite end of the maturity scale. So the idea of it demolishing Google's ad revenue seems fanciful.

## A new Google Search interface?

Also, Google could choose to develop an advanced version of ChatGPT, offer it as a search interface option, and monetize it. So where's the "existential" threat?

Consider for starters, that when you sign up for OpenAI.com (in order to use ChatGPT) you can sign in with your Gmail account. That's one avenue to monetization: capture identity (assign a unique identifier to each user) and couple it to queries. 

And there's nothing preventing a service like ChatGPT from posting ads on its pages. 

## ChatGPT vs Google Search

In comparing ChatGPT with Google, it's worth noting what the former doesn't do.

For example, ChatGPT can't access the internet to retrieve information. And it doesn't provide users with clickable references to verify sources and accuracy. 

It could though, if it became an OpenAI-search engine hybrid, like <a href="https://www.perplexity.ai/" target="blank">Perplexity.ai</a>. The latter includes clickable footnotes and citations with its answers.

<img src="https://res.cloudinary.com/icecloud7/image/upload/v1672454812/SignalFox/perplexity-ai_is865c.png" />

Also consider that countless queries are made on Google Search for up-to-date stock prices, tickets, event times, train and flight schedules, traffic delays, products, and more. 

Development of schema and structured data has given us interactive search results like these. (They look like ads but they're not.) Hover over a jacket and you'll get 5 images that fade in and out, showing multiple angles. 

<img src="https://res.cloudinary.com/icecloud7/image/upload/f_auto/v1672430369/SignalFox/lambskin-bomber-jacket_af9b7s.png" />

But ChatGPT can't answer queries like this: 

<img src="https://res.cloudinary.com/icecloud7/image/upload/f_auto/v1672431118/SignalFox/chatgpt-prices-ratings_obyx7r.png" />

Or like this: 

<img src="https://res.cloudinary.com/icecloud7/image/upload/v1672430632/SignalFox/chatgpt-limitations_oocptj.png" />

It also doesn't proactively make suggestions: it waits for you to ask a question.

This is in contast to Google Search which through auto-suggest and personalized search results, is always making recommendations based on your interactions with it.

And how likely is it that people will suddenly want text only and lose their interest in browsing video, audio, and images?

The point isn't that ChatGPT should be more like Google. It's to underscore the fact that both products serve different purposes, although there is overlap, as in providing encyclopedia-style facts.

<a href="https://research.google/people/107923/" target="blank">Zoubin Ghahramani</a>, leader of <a href="https://research.google/teams/brain/" target="blank">Google Brain</a>, put it well when he told the _Times_ last month: 

<div style="padding-left: 2.5em;"><p>A cool demo of a conversational system that people can interact with over a few rounds, and it feels mind-blowing? That is a good step, but it is not the thing that will really transform society. It is not something that people can use reliably on a daily basis.</p></div>

Sam Altman, CEO of OpenAI <a href="https://twitter.com/sama/status/1601731295792414720?s=20&t=pM3JTMZ-D8-Qw5q-TXsA8w" target="blank">concurs</a>.

The _Times_ article seems speculative at best. Nevertheless, some SEO professionals are playing up the 'Code Red threat' in their social media comments.

For fun, let's give the robot the last word.

<img src="https://res.cloudinary.com/icecloud7/image/upload/f_auto/e_sharpen/v1672429135/SignalFox/chatgpt-code-red_u3i0vk.png" />

<br/><br/><hr/>
<p id="footnote-1">
1. AI Chatbots can produce "<a href="https://en.wikipedia.org/wiki/Hallucination_(artificial_intelligence)#:~:text=In%20artificial%20intelligence%2C%20a%20hallucination,justified%20by%20its%20training%20data." target="blank">hallucinations</a>", known colloquially as "<a href="https://twitter.com/jdwalters85/status/1608661137738063874" target="blank">confident B.S.</a>" <a href="#footnote-1-ref">↑</a> 
</p>


